---
title: "Homework 1"
author: "CS 498, Spring 2018, Xiaoming Ji"
date: ''
output:
  html_document:
    toc: yes
  pdf_document: default
---


#Problem 1

##Part A
Build a simple naive Bayes classifier to classify this data set. We will use 20% of the data for evaluation and the other 80% for training. There are a total of 768 data-points.

We use a normal distribution to model each of the class-conditional distributions. 

```{r}
#Prepare training and testing data
library(readr)
all_data  = read.csv("pima-indians-diabetes.data.csv", header = FALSE)
```

We define a function to train naive Byaes model by calculating p(y=class) and mean and standard deviation of feature variables for each class.

```{r}
gnb.fit = function(features, labels) {
  model      = list("p_y", "mu","sigma")
  class_val  = unique(labels)
  class_num  = max(class_val) + 1
  record_num = length(labels)

  p_y       = rep(0, class_num)
  mu        = array(0, c(class_num, dim(features)[2]))
  sigma     = array(0, c(class_num, dim(features)[2]))
  
  for (y in class_val) {
    indexes = labels == y
    p_y[y + 1]  = length(labels[indexes]) / record_num
    
    x             = features[indexes,]
    mu[y + 1,]    = sapply(x, mean, na.rm=TRUE)
    sigma[y + 1,] = sapply(x, sd, na.rm=TRUE)
  }
  
  model$p_y = p_y
  model$mu = mu
  model$sigma = sigma
  
  return (model)
}
```

Since we use normal distribution for each feature $x_j$, the probability of $x_j$ given class $y_k$ is given as,
$$
p(x_j|y_k) = \frac{1}{{\sigma_k \sqrt {2\pi }}}e^-\frac{{\left({x - \mu_k} \right)^2}}{2\sigma_k^2}
$$
where $\mu_k$ and $\sigma_k$ are mean and stanstard deviation of feature $x_j$ for a given class $y_k$. They are calculated by function *gnb.fit*.

To calculate the log probablity of one class $y_k$, we use formula,
$$
\sum_jlog(x_j|y_k) + logp(y_k) 
$$ 
$$
= -\sum_j(log\sigma_k + log\sqrt{2\pi} + \frac{\left(x - \mu_k\right)^2}{2\sigma_k^2}) + logp(y_k)
$$
Given $log\sqrt{2\pi}$ is contant, we have,
$$
\propto -\sum_j(log\sigma_k+ \frac{\left(x - \mu_k\right)^2}{2\sigma_k^2}) + logp(y_k)
$$ 

We define a function to predict the class given a model and features.
```{r}
gnb.predict = function(model, x) {
  class_num = length(model$p_y)
  y_score = array(0, c(dim(x)[1],class_num))
  
  for (i in 1:class_num) {
    scale       = (t(x)-model$mu[i,])/model$sigma[i,]
    logs        = -(log(model$sigma[i,]) + (1/2) * scale ^ 2)
    y_score[,i] = colSums(logs, na.rm = TRUE) + log(model$p_y[i])
  }
  
  return (max.col(y_score) - 1)
}
```

Let's train and check the accuracy of the classifier on the 20% evaluation data. We will do 10-fold cross-validation and select the best model for testing evaluation data.

```{r}
#Do cross validation and return best model
cross_validation = function(x, y, fold_num) {
  train_num = length(y)
  accuracy  = rep(0, fold_num)
  models    = list()

  valid_num = round(train_num / fold_num)
  for (i in 1:fold_num){
    index_from = (i - 1) * valid_num + 1
    index_to   = i * valid_num + 1
    if(index_to > train_num) index_to = train_num
                                                           
    valid_indexes = index_from : index_to
    train_x = x[-valid_indexes, ]
    train_y = y[-valid_indexes]
    valid_x = x[valid_indexes, ]
    valid_y = y[valid_indexes]
    
    models[[i]] = gnb.fit(train_x, train_y)
    pred_y = gnb.predict(models[[i]], valid_x)
    
    accuracy[i] = sum(pred_y == valid_y) / length(valid_y)
    #print(accuracy[i])
  }
  
  #print(which.max(accuracy))
  return (models[[which.max(accuracy)]])
}

set.seed(19720816)
fold_num = 10
train_indexes = sample(1:dim(all_data)[1], round(dim(all_data)[1] * 0.8))

best_model = cross_validation(all_data[train_indexes,-c(9)], all_data[train_indexes,c(9)], 10)

test_x = all_data[-train_indexes,-c(9)]
test_y = all_data[-train_indexes,c(9)]
pred_y = gnb.predict(best_model, test_x)
best_accuracy = sum(pred_y == test_y)/length(test_y)
```

We got accuracy: $`r best_accuracy`$

##Part B
We will adjust our code so that, for attribute 3 (Diastolic blood pressure), attribute 4 (Triceps skin fold thickness), attribute 6 (Body mass index), and attribute 8 (Age), it regards a value of 0 as a missing value when estimating the class-conditional distributions, and the posterior. R uses a special number NA to flag a missing value. 

```{r}
all_x_na = all_data

for (i in c(3, 5, 6, 8))
{
  index = all_x_na[, i]==0
  all_x_na[index, i] = NA
}

set.seed(19720816)
fold_num = 10
train_indexes = sample(1:dim(all_x_na)[1], round(dim(all_x_na)[1] * 0.8))

best_model = cross_validation(all_x_na[train_indexes,-c(9)], all_x_na[train_indexes,c(9)], 10)

test_x = all_x_na[-train_indexes,-c(9)]
test_y = all_x_na[-train_indexes,c(9)]
pred_y = gnb.predict(best_model, test_x)
best_accuracy = sum(pred_y == test_y)/length(test_y)
```

We got accuracy: $`r best_accuracy`$. The result don't have much difference compared with the previous one.

##Part C
Use the caret and klaR packages to build a naive bayes classifier for this data, assuming that no attribute has a missing value. We will do 10-fold cross-validation and test the accuracy of the classifier on the held out 20%.

```{r, message=FALSE, warning=FALSE}
library(caret)

train_indexes = createDataPartition(y = all_data[, 9], p = 0.8, list = FALSE)
train_x = all_data[train_indexes,-c(9)]
train_y = as.factor(all_data[train_indexes,c(9)])
model   = train(train_x, train_y, 'nb', trControl = trainControl(method='cv', number=10))

test_x = all_data[-train_indexes,-c(9)]
test_y = all_data[-train_indexes,c(9)]
pred_y = predict(model, newdata = test_x)
accuracy = sum(pred_y == test_y)/length(test_y)
```
We got accuracy: $`r accuracy`$

##Part D
Now we use SVMLight to train and evaluate an SVM to classify this data.

```{r, message=FALSE}
library(klaR)

train_indexes = createDataPartition(y = all_data[, 9], p = 0.8, list = FALSE)
train_x = all_data[train_indexes,-c(9)]
train_y = all_data[train_indexes,c(9)]

model = svmlight(train_x, train_y, pathsvm="./svmlight")

test_x = all_data[-train_indexes,-c(9)]
test_y = all_data[-train_indexes,c(9)]
pred_y = predict(model, newdata = test_x)
accuracy = sum(pred_y$class == test_y)/length(test_y)
```

We got accuracy: $`r accuracy`$

#Problem 2

##Part A

##Part B